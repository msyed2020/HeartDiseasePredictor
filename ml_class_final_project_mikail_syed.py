# -*- coding: utf-8 -*-
"""ML Class Final Project - Mikail Syed.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EHmGyvpFBnY0L0oHNX7JBf2xnje2n35A
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

import pandas as pd
import numpy as np

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

data = pd.read_csv('heart.csv') # Make EXTRA EXTRA sure you have heart.csv loaded into this before this is run

X = data.drop('target', axis=1)
y = data['target']

X = X.values
y = y.values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.float32)
X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
y_test_tensor = torch.tensor(y_test, dtype=torch.float32)

train_dataset = list(zip(X_train_tensor, y_train_tensor))
test_dataset = list(zip(X_test_tensor, y_test_tensor))

from torch.utils.data import DataLoader

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

for batch_size, (features, targets) in enumerate(train_loader):
    print(f"Batch: {batch_size + 1}\nFeatures: {features.shape}\nTargets: {targets.shape}")
    break

class Model(nn.Module):
  def __init__(self, input_dim):
    super(Model, self).__init__()
    self.fc1 = nn.Linear(input_dim, 64)
    self.relu = nn.ReLU()
    self.fc2 = nn.Linear(64, 32)
    self.fc3 = nn.Linear(32, 1)
    self.sigmoid = nn.Sigmoid()
    # self.layers = nn.Sequential( # Reformatted in attempt to add more layers
    #     nn.Linear(input_dim, 64),
    #     nn.ReLU(),
    #     nn.Linear(64, 32),
    #     nn.Linear(32, 1),
    #     nn.Sigmoid()
    # )

  # Add more layers to potentially fix accuracy
  def forward(self, x):
    x = self.relu(self.fc1(x))
    x = self.relu(self.fc2(x))
    x = self.sigmoid(self.fc3(x))
    return x

input_dim = X_train_tensor.shape[1]
model = Model(input_dim)

lossFunc = nn.BCEWithLogitsLoss()
optim = torch.optim.Adam(model.parameters(), lr=0.0001)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

epochs = 25 # Inspired by HW4 lol

train_loss_arr = []
train_acc_arr = []
test_loss_arr = []
test_acc_arr = []

for epoch in range(epochs):
    model.train()
    train_loss = 0.0
    train_acc = 0.0

    for batch, (X, y) in enumerate(train_loader):
        X, y = X.to(device), y.to(device).view(-1, 1)
        y_pred = model(X)
        loss = lossFunc(y_pred, y)
        train_loss += loss.item()
        optim.zero_grad()
        loss.backward()
        optim.step()
        y_pred_class = (y_pred > 0.5).float()
        correct = (y_pred_class == y).sum().item()
        accuracy = correct / y.size(0)
        train_acc += accuracy

    train_loss_arr.append(train_loss / len(train_loader))
    train_acc_arr.append((train_acc / len(train_loader)) * 100)


    model.eval()
    test_loss = 0.0
    test_acc = 0.0

    with torch.no_grad():
        for X, y in test_loader:
            X, y = X.to(device), y.to(device).view(-1, 1)

            y_pred = model(X)


            loss = lossFunc(y_pred, y)
            test_loss += loss.item()


            y_pred_class = (y_pred > 0.5).float()
            correct = (y_pred_class == y).sum().item()
            accuracy = correct / y.size(0)
            test_acc += accuracy


    test_loss_arr.append(test_loss / len(test_loader))
    test_acc_arr.append((test_acc / len(test_loader)) * 100)


    # Print epoch metrics
    print(f"Epoch {epoch+1}/{epochs}, Loss: {train_loss_arr[-1]:.4f}, Train Accuracy: {train_acc_arr[-1]:2f}%, ")

    print(f"Test Loss: {test_loss_arr[-1]:.4f}, Test Accuracy: {test_acc_arr[-1]:2f}%")

torch.save(model.state_dict(), "mikailsyedfinalproject.pth")

import matplotlib.pyplot as plt

# Loss plotting
plt.figure(figsize=(10, 5))
plt.plot(train_loss_arr, label='Train Loss')
plt.plot(test_loss_arr, label='Test Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Over Epochs')
plt.legend()
plt.show()

# Accuracy Plotting
plt.figure(figsize=(10, 5))
plt.plot(train_acc_arr, label='Train Accuracy')
plt.plot(test_acc_arr, label='Test Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy (%)')
plt.title('Accuracy Over Epochs')
plt.legend()
plt.show()

pip install graphviz

from graphviz import Digraph

# Initialize Digraph
dot = Digraph(comment="Project Workflow")

# Define steps
dot.node("A", "Load Cleveland Dataset, 1988")
dot.node("B", "Clean Data")
dot.node("C", "Split Data (Train/Test), Process into Data Loader")
dot.node("D", "Define Heart Disease Model")
dot.node("E", "Train Model with Data")
dot.node("F", "Evaluate Model with Data")
dot.node("G", "Plot Results")

# Connect steps
dot.edges(["AB", "BC", "CD", "DE", "EF", "FG"])

# Render and visualize
dot.render("workflow_diagram", format="png", cleanup=True)
dot.view()